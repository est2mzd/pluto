# custom_datamodule.py è©³ç´°è§£èª¬

## ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æ¦‚è¦

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€PyTorch Lightning ã® `LightningDataModule` ã‚’æ‹¡å¼µã—ã€PLUTOãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã®ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚’è¡Œã„ã¾ã™ã€‚

**ä¸»ãªè²¬å‹™ï¼š**
- è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªã‚’train/val/testã«åˆ†å‰²
- å„ã‚»ãƒƒãƒˆã®ç‰¹å¾´é‡ã‚’è¨ˆç®—ãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥
- DataLoader ã‚’ä½œæˆã—ã¦ PyTorch Lightning ã«æä¾›

---

## ğŸ”§ ä¸»è¦ã‚¯ãƒ©ã‚¹ãƒ»é–¢æ•°

### 1. `create_dataset()` é–¢æ•°

#### å½¹å‰²
è¤‡æ•°ã®ã‚·ãƒŠãƒªã‚ªã‹ã‚‰ã€æŒ‡å®šã•ã‚ŒãŸå‰²åˆã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦Datasetã‚’ä½œæˆã—ã¾ã™ã€‚

#### ã‚·ã‚°ãƒãƒãƒ£
```python
def create_dataset(
    samples: List[AbstractScenario],           # å…¨ã‚·ãƒŠãƒªã‚ª
    feature_preprocessor: FeaturePreprocessor, # ç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³
    dataset_fraction: float,                   # ä½¿ç”¨å‰²åˆï¼ˆ0.0ï½1.0ï¼‰
    dataset_name: str,                         # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåï¼ˆtrain/val/testï¼‰
    augmentors: Optional[List[AbstractAugmentor]] = None  # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
) -> torch.utils.data.Dataset:
```

#### å‡¦ç†ãƒ•ãƒ­ãƒ¼
```
å…¥åŠ›: 100å€‹ã®ã‚·ãƒŠãƒªã‚ªã€dataset_fraction=0.5
     â†“
1. num_keep = 100 * 0.5 = 50
2. 100å€‹ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«50å€‹ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
     â†“
å‡ºåŠ›: 50å€‹ã®ã‚·ãƒŠãƒªã‚ªã‚’å«ã‚€ Dataset
```

#### ä¾‹
```python
# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆï¼ˆå…¨ã‚·ãƒŠãƒªã‚ªã®60%ã‚’ä½¿ç”¨ï¼‰
train_dataset = create_dataset(
    samples=train_scenarios,
    feature_preprocessor=preprocessor,
    dataset_fraction=0.6,
    dataset_name="train",
    augmentors=[AugmentorA(), AugmentorB()]
)
```

---

### 2. `distributed_weighted_sampler_init()` é–¢æ•°

#### å½¹å‰²
ã‚·ãƒŠãƒªã‚ªã‚¿ã‚¤ãƒ—ã”ã¨ã«ç•°ãªã‚‹ç¢ºç‡ã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã€Œé‡ã¿ä»˜ãã‚µãƒ³ãƒ—ãƒ©ãƒ¼ã€ã‚’ä½œæˆã—ã¾ã™ã€‚

#### èƒŒæ™¯
è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ãªã‚·ãƒŠãƒªã‚ªã‚¿ã‚¤ãƒ—ãŒæ··åœ¨ã—ã¦ã„ã¾ã™ï¼š
- ç›´ç·šèµ°è¡Œã‚·ãƒŠãƒªã‚ª: å¤šæ•°
- äº¤å·®ç‚¹ã‚·ãƒŠãƒªã‚ª: å°‘æ•°
- æ¸‹æ»ã‚·ãƒŠãƒªã‚ª: å°‘æ•°

**å•é¡Œ**: ãã®ã¾ã¾å­¦ç¿’ã™ã‚‹ã¨ã€ç›´ç·šèµ°è¡Œã‚·ãƒŠãƒªã‚ªã°ã‹ã‚Šå­¦ç¿’ã—ã¾ã™

**è§£æ±º**: é‡ã¿ä»˜ãã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
```
ç›´ç·šèµ°è¡Œ: é‡ã¿=1.0 â†’ 50%ã®ç¢ºç‡ã§é¸ã°ã‚Œã‚‹
äº¤å·®ç‚¹:   é‡ã¿=2.0 â†’ 40%ã®ç¢ºç‡ã§é¸ã°ã‚Œã‚‹
æ¸‹æ»:     é‡ã¿=2.0 â†’ 10%ã®ç¢ºç‡ã§é¸ã°ã‚Œã‚‹
```

#### ã‚·ã‚°ãƒãƒãƒ£
```python
def distributed_weighted_sampler_init(
    scenario_dataset: ScenarioDataset,  # å¯¾è±¡Dataset
    scenario_sampling_weights: Dict[str, float],  # ã‚·ãƒŠãƒªã‚ªã‚¿ã‚¤ãƒ—â†’é‡ã¿ã®è¾æ›¸
    replacement: bool = True  # å¾©å…ƒæŠ½å‡ºï¼ˆTrueãªã‚‰åŒã˜ã‚·ãƒŠãƒªã‚ªã‚’è¤‡æ•°å›é¸æŠå¯èƒ½ï¼‰
) -> WeightedRandomSampler:
```

#### ä¾‹
```python
# ã‚·ãƒŠãƒªã‚ªã‚¿ã‚¤ãƒ—åˆ¥ã®é‡ã¿
weights = {
    "straight": 1.0,
    "intersection": 2.0,
    "congestion": 2.0
}

sampler = distributed_weighted_sampler_init(
    scenario_dataset=dataset,
    scenario_sampling_weights=weights,
    replacement=True
)
```

---

### 3. `CustomDataModule` ã‚¯ãƒ©ã‚¹

#### å½¹å‰²
PyTorch Lightning ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚’ã™ã¹ã¦å®Ÿè£…ã—ã¾ã™ã€‚

#### ã‚¯ãƒ©ã‚¹å›³
```
LightningDataModuleï¼ˆæŠ½è±¡åŸºåº•ã‚¯ãƒ©ã‚¹ï¼‰
    â†‘
    â”‚ ç¶™æ‰¿
    â”‚
CustomDataModule
```

#### ä¸»è¦ãªãƒ¡ã‚½ãƒƒãƒ‰

##### `__init__()` - åˆæœŸåŒ–
```python
def __init__(
    self,
    feature_preprocessor: FeaturePreprocessor,     # ç‰¹å¾´é‡è¨ˆç®—
    splitter: AbstractSplitter,                    # train/val/teståˆ†å‰²å™¨
    all_scenarios: List[AbstractScenario],         # å…¨ã‚·ãƒŠãƒªã‚ª
    train_fraction: float,                         # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨å‰²åˆ
    val_fraction: float,                           # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨å‰²åˆ
    test_fraction: float,                          # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½¿ç”¨å‰²åˆ
    dataloader_params: Dict[str, Any],             # DataLoaderãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    scenario_type_sampling_weights: DictConfig,    # ã‚·ãƒŠãƒªã‚ªé‡ã¿è¨­å®š
    worker: WorkerPool,                            # ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ãƒƒã‚·ãƒ³ã‚°ç”¨
    augmentors: Optional[List[AbstractAugmentor]] = None  # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
) -> None:
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è§£èª¬:**

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | èª¬æ˜ | ä¾‹ |
|-----------|------|-----|
| `feature_preprocessor` | ç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³ | `FeaturePreprocessor(...)` |
| `splitter` | ã‚·ãƒŠãƒªã‚ªã‚’åˆ†å‰² | `RandomSplitter()` |
| `all_scenarios` | å…¨ã‚·ãƒŠãƒªã‚ªãƒªã‚¹ãƒˆ | `[scenario1, scenario2, ...]` |
| `train_fraction` | è¨“ç·´ã«ä½¿ã†å‰²åˆ | `0.7` = 70% |
| `val_fraction` | æ¤œè¨¼ã«ä½¿ã†å‰²åˆ | `0.15` = 15% |
| `test_fraction` | ãƒ†ã‚¹ãƒˆã«ä½¿ã†å‰²åˆ | `0.15` = 15% |
| `dataloader_params` | DataLoaderã®è¨­å®š | `{"batch_size": 32, "num_workers": 4}` |
| `scenario_type_sampling_weights` | ã‚·ãƒŠãƒªã‚ªã‚¿ã‚¤ãƒ—åˆ¥é‡ã¿ | `{"straight": 1.0, "intersection": 2.0}` |
| `worker` | ä¸¦åˆ—å‡¦ç†ç”¨ãƒ¯ãƒ¼ã‚«ãƒ¼ | `WorkerPool(num_workers=8)` |
| `augmentors` | ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæ‰‹æ³• | `[RandomRotation(), RandomFlip()]` |

##### `setup()` - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™
```python
def setup(self, stage: Optional[str] = None) -> None:
```

**å‘¼ã°ã‚Œã‚‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°:**
- `stage="fit"` â†’ è¨“ç·´ãƒ»æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™
- `stage="validate"` â†’ æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã¿æº–å‚™
- `stage="test"` â†’ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™

**å†…éƒ¨å‡¦ç†:**
```
stage="fit" ã®å ´åˆ:
    â†“
1. splitter.get_train_samples() â†’ è¨“ç·´ç”¨ã‚·ãƒŠãƒªã‚ªå–å¾—
2. create_dataset() â†’ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
3. splitter.get_val_samples() â†’ æ¤œè¨¼ç”¨ã‚·ãƒŠãƒªã‚ªå–å¾—
4. create_dataset() â†’ æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
    â†“
self._train_set ã¨ self._val_set ã«ä¿å­˜
```

##### `train_dataloader()` - è¨“ç·´ç”¨DataLoaderç”Ÿæˆ
```python
def train_dataloader(self) -> torch.utils.data.DataLoader:
```

**å‹•ä½œ:**
1. è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒæº–å‚™æ¸ˆã¿ã‹ç¢ºèª
2. ã‚·ãƒŠãƒªã‚ªé‡ã¿è¨­å®šãŒæœ‰åŠ¹ãªã‚‰ã€é‡ã¿ä»˜ãã‚µãƒ³ãƒ—ãƒ©ãƒ¼ã‚’ä½œæˆ
3. DataLoader ã‚’è¿”ã™

**é‡è¦:** è¨“ç·´æ™‚ã®ã‚·ãƒ£ãƒƒãƒ•ãƒ«æ–¹æ³•
```python
# é‡ã¿ä»˜ãã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒæœ‰åŠ¹ â†’ é‡ã¿ä»˜ãã‚µãƒ³ãƒ—ãƒ©ãƒ¼ä½¿ç”¨
if self._scenario_type_sampling_weights.enable:
    sampler = distributed_weighted_sampler_init(...)
    return DataLoader(shuffle=False, sampler=sampler, ...)  # samplerã‚’ä½¿ç”¨

# é‡ã¿ä»˜ãã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒç„¡åŠ¹ â†’ ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ£ãƒƒãƒ•ãƒ«
else:
    return DataLoader(shuffle=True, sampler=None, ...)  # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ£ãƒƒãƒ•ãƒ«
```

##### `val_dataloader()` - æ¤œè¨¼ç”¨DataLoaderç”Ÿæˆ
```python
def val_dataloader(self) -> torch.utils.data.DataLoader:
```

**ç‰¹å¾´:**
- ã‚·ãƒ£ãƒƒãƒ•ãƒ«ãªã—ï¼ˆå¸¸ã«åŒã˜é †åºï¼‰
- é‡ã¿ä»˜ãã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãªã—ï¼ˆé †åºé€šã‚Šã«ä½¿ç”¨ï¼‰

##### `test_dataloader()` - ãƒ†ã‚¹ãƒˆç”¨DataLoaderç”Ÿæˆ
```python
def test_dataloader(self) -> torch.utils.data.DataLoader:
```

**ç‰¹å¾´:**
- æ¤œè¨¼æ™‚ã¨åŒæ§˜ã€ã‚·ãƒ£ãƒƒãƒ•ãƒ«ãªã—

##### `transfer_batch_to_device()` - GPU/CPUè»¢é€
```python
def transfer_batch_to_device(
    self,
    batch: Tuple[FeaturesType, ...],  # ãƒãƒƒãƒ
    device: torch.device,              # è»¢é€å…ˆï¼ˆGPU/CPUï¼‰
    dataloader_idx: int
) -> Tuple[FeaturesType, ...]:
```

**å½¹å‰²:**
ãƒãƒƒãƒã‚’GPUãƒ¡ãƒ¢ãƒªã«è»¢é€ï¼ˆè¤‡æ•°ã®ãƒ†ãƒ³ã‚½ãƒ«ã‚’æ­£ã—ãè»¢é€ï¼‰

```python
# PyTorch Lightning ãŒè‡ªå‹•ã§å‘¼ã³å‡ºã™
batch = (features_tensor, targets_tensor, metadata)
batch_on_gpu = module.transfer_batch_to_device(batch, device=torch.device('cuda'))
```

---

## ğŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ï¼ˆè©³ç´°ç‰ˆï¼‰

```
ã€åˆæœŸåŒ–ã€‘
custom_training_builder.py
  â†“
build_lightning_datamodule()
  â†“
CustomDataModule.__init__()  â† åˆæœŸåŒ–ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæœªä½œæˆï¼‰


ã€å­¦ç¿’é–‹å§‹ã€‘
PyTorch Lightning
  â†“
trainer.fit(model, datamodule)
  â†“
datamodule.setup(stage="fit")  â† ã“ã“ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
  â”œâ”€ splitter.get_train_samples()
  â”œâ”€ create_dataset() â†’ self._train_set
  â”œâ”€ splitter.get_val_samples()
  â””â”€ create_dataset() â†’ self._val_set


ã€å„ã‚¨ãƒãƒƒã‚¯ã€‘
for epoch in range(max_epochs):
  â”œâ”€ train_dataloader() â†’ ãƒãƒƒãƒå–å¾—
  â”‚   â”œâ”€ é‡ã¿ä»˜ãã‚µãƒ³ãƒ—ãƒ©ãƒ¼ã§å„ªå…ˆåº¦ä»˜ãã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
  â”‚   â”œâ”€ ãƒãƒƒãƒä½œæˆ
  â”‚   â””â”€ transfer_batch_to_device() ã§ GPUè»¢é€
  â”‚
  â””â”€ val_dataloader() â†’ ãƒãƒƒãƒå–å¾—
      â”œâ”€ é †åºé€šã‚Šã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
      â”œâ”€ ãƒãƒƒãƒä½œæˆ
      â””â”€ transfer_batch_to_device() ã§ GPUè»¢é€
```

---

## ğŸ’¡ å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ

### 1. Lazy Initialization ãƒ‘ã‚¿ãƒ¼ãƒ³
```python
# __init__ã§ã¯ None ã§åˆæœŸåŒ–
self._train_set: Optional[torch.utils.data.Dataset] = None

# setup() ãŒå‘¼ã°ã‚Œã‚‹ã¾ã§å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ãªã„
# ãƒ¡ãƒªãƒƒãƒˆ: åˆæœŸåŒ–ãŒé«˜é€Ÿ
```

### 2. åˆ†æ•£å­¦ç¿’å¯¾å¿œ
```python
# DistributedSamplerWrapper ã‚’ä½¿ç”¨
distributed_weighted_sampler = DistributedSamplerWrapper(weighted_sampler)

# è¤‡æ•°GPUã§å­¦ç¿’ã™ã‚‹å ´åˆã‚‚ã€å„GPUãŒæ­£ã—ããƒ‡ãƒ¼ã‚¿ã‚’åˆ†æ‹…
```

### 3. ãƒ•ã‚£ãƒ¼ãƒãƒ£è¨ˆç®—ã®ä¸¦åˆ—åŒ–
```python
# feature_preprocessor ãŒåŠ¹ç‡çš„ã«ç‰¹å¾´é‡ã‚’è¨ˆç®—
# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ´»ç”¨ã—ã¦å†è¨ˆç®—ã‚’é¿ã‘ã‚‹
```

---

## ğŸ¨ ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºä¾‹

### ä¾‹1: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®è¿½åŠ 
```python
augmentors = [
    RandomRotation(degrees=15),
    RandomNoise(std=0.1),
    RandomCrop(size=(128, 128))
]

datamodule = CustomDataModule(
    ...,
    augmentors=augmentors
)
```

### ä¾‹2: ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å‡¦ç†
```python
# ã‚·ãƒŠãƒªã‚ªã‚¿ã‚¤ãƒ—åˆ¥ã®é‡ã¿è¨­å®š
scenario_type_sampling_weights = {
    "highway": 1.0,       # ä¸€èˆ¬çš„
    "intersection": 3.0,  # é‡è¦åº¦é«˜
    "accident": 5.0,      # æœ€ã‚‚é‡è¦
}

# é‡ã„ã‚·ãƒŠãƒªã‚ªã»ã©å¤šãè¨“ç·´ã«ä½¿ç”¨
```

---

## ğŸ› ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨å¯¾å‡¦

### Error: `DataModuleNotSetupError`
```
åŸå› : setup() ãŒå‘¼ã°ã‚Œã‚‹å‰ã« train_dataloader() ã‚’å‘¼ã³å‡ºã—ãŸ
è§£æ±º: PyTorch Lightning ãŒè‡ªå‹•çš„ã« setup() ã‚’å‘¼ã¶ã®ã§ã€é€šå¸¸ã¯ç™ºç”Ÿã—ãªã„
```

### Error: `AssertionError: Train fraction has to be larger than 0!`
```
åŸå› : train_fraction=0.0 ã§åˆæœŸåŒ–ã—ãŸ
è§£æ±º: train_fraction > 0 ã«ã™ã‚‹
```

### Warning: `All scenario sampling weights must be positive`
```
åŸå› : ã‚·ãƒŠãƒªã‚ªã‚¿ã‚¤ãƒ—ã®é‡ã¿ãŒè² ã®å€¤
è§£æ±º: å…¨ã¦ã®é‡ã¿ã‚’æ­£ã®å€¤ã«ã™ã‚‹
```

---

## ğŸ“š é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«

- [custom_training_builder.py](./custom_training_builder.md) - å…¨ä½“çµ±åˆ
- [../../../config/default_training.yaml](../../../config/default_training.yaml) - è¨­å®š
- [../../../run_training.py](../../../run_training.py) - ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
