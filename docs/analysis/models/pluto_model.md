# PlutoModel ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ è©³ç´°ã‚¬ã‚¤ãƒ‰

## ğŸ“‹ æ¦‚è¦

`PlutoModel` ã¯ã€**ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è»Œè·¡äºˆæ¸¬** ã‚’è¡Œã†ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚

---

## ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å…¨ä½“

### æ§‹æˆå›³

```
ã€å…¥åŠ›å±¤ã€‘
    â”œâ”€ Ego çŠ¶æ…‹: [x, y, yaw, vx, vy, ax, ay, ...]
    â”œâ”€ å‘¨è¾ºã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: (64, 101, 10) â† ä½ç½®ã€é€Ÿåº¦ã€å½¢çŠ¶ãªã©
    â”œâ”€ ãƒãƒƒãƒ—: ãƒãƒªã‚´ãƒ³ã€ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¬ã‚¤ãƒ¤ãƒ¼
    â””â”€ ã‚³ã‚¹ãƒˆåœ°å›³: occupancy grid (500, 500)

            â†“ æ­£è¦åŒ–ãƒ»ç‰¹å¾´æŠ½å‡º

ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã€‘
    â”œâ”€ Ego Encoder
    â”‚   â”œâ”€ MLP: 10 â†’ 128 â†’ 256
    â”‚   â””â”€ å‡ºåŠ›: (1, 256)
    â”‚
    â”œâ”€ Agent Encoder (64ä¸¦åˆ—)
    â”‚   â”œâ”€ LSTM: è»Œè·¡æ™‚ç³»åˆ—å‡¦ç† (101, 10) â†’ 256
    â”‚   â”œâ”€ Self-Attention: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®ç›¸äº’ä½œç”¨
    â”‚   â””â”€ å‡ºåŠ›: (64, 256)
    â”‚
    â”œâ”€ Map Encoder
    â”‚   â”œâ”€ GNN: ãƒãƒªã‚´ãƒ³ã‚°ãƒ©ãƒ•ã®å‡¦ç†
    â”‚   â”œâ”€ Graph Attention: ãƒãƒƒãƒ—è¦ç´ ã®ç›¸äº’ä½œç”¨
    â”‚   â””â”€ å‡ºåŠ›: (num_nodes, 256)
    â”‚
    â””â”€ Fusion
        â”œâ”€ Ego + Agent + Map ã®ç‰¹å¾´é‡çµ±åˆ
        â”œâ”€ Cross-Attention: ãƒ¢ãƒ€ãƒªãƒ†ã‚£é–“ã®ç›¸äº’ä½œç”¨
        â””â”€ å‡ºåŠ›: (1, 512)

            â†“ Context Vector

ã€ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã€‘
    â”œâ”€ Trajectory Generation Mode 1
    â”‚   â”œâ”€ MLP Decoder: 512 â†’ 256 â†’ 128
    â”‚   â”œâ”€ è»Œè·¡ç”Ÿæˆ: (80, 3) = (x, y, yaw)
    â”‚   â””â”€ å‡ºåŠ›: (80, 3)
    â”‚
    â”œâ”€ Trajectory Generation Mode 2
    â”‚   â””â”€ åŒä¸Š
    â”‚
    â”œâ”€ ... Mode K
    â”‚   â””â”€ åŒä¸Š
    â”‚
    â””â”€ Confidence Head
        â”œâ”€ MLP: 512 â†’ 256 â†’ K
        â””â”€ Softmax: (K,) â† ãƒ¢ãƒ¼ãƒ‰ç¢ºç‡

ã€å‡ºåŠ›å±¤ã€‘
    â”œâ”€ predictions: (num_agents, K, 80, 3)
    â”œâ”€ confidence: (num_agents, K)
    â””â”€ auxiliary: {æ´»æ€§åŒ–ãƒãƒƒãƒ—ãªã©}
```

---

## ğŸ”§ å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è©³ç´°å®Ÿè£…

### Ego Encoder

```python
class EgoEncoder(nn.Module):
    def __init__(self, state_dim: int = 10, hidden_dim: int = 256):
        super().__init__()
        self.mlp = nn.Sequential(
            nn.Linear(state_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 256),
            nn.ReLU(),
            nn.Linear(256, hidden_dim)
        )
        # å‡ºåŠ›: (hidden_dim,)
    
    def forward(self, ego_state: torch.Tensor) -> torch.Tensor:
        """
        Args:
            ego_state: (batch, 10) â† [x, y, yaw, vx, vy, ax, ay, steer, steer_rate, ...]
        
        Returns:
            ego_embedding: (batch, hidden_dim)
        """
        return self.mlp(ego_state)
```

### Agent Encoder

```python
class AgentEncoder(nn.Module):
    def __init__(self, hidden_dim: int = 256):
        super().__init__()
        # æ™‚ç³»åˆ—å‡¦ç†
        self.lstm = nn.LSTM(
            input_size=10,      # [x, y, vx, vy, yaw, ...] Ã— 2 (ç›¸å¯¾ãƒ»çµ¶å¯¾)
            hidden_size=256,
            num_layers=2,
            batch_first=True
        )
        
        # è‡ªå·±æ³¨æ„æ©Ÿæ§‹ï¼ˆç•°ãªã‚‹æ™‚åˆ»ã§ã®é–¢é€£æ€§ã‚’å­¦ç¿’ï¼‰
        self.temporal_attention = nn.MultiheadAttention(
            embed_dim=256,
            num_heads=8,
            batch_first=True
        )
    
    def forward(
        self,
        agent_trajectories: torch.Tensor,
        valid_mask: torch.Tensor
    ) -> torch.Tensor:
        """
        Args:
            agent_trajectories: (batch, num_agents, time=101, 10)
            valid_mask: (batch, num_agents) â† ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æœ‰åŠ¹æ€§
        
        Returns:
            agent_embeddings: (batch, num_agents, hidden_dim)
        """
        batch, num_agents, T, _ = agent_trajectories.shape
        
        # LSTM ã«ã‚ˆã‚‹æ™‚ç³»åˆ—ç¬¦å·åŒ–
        lstm_out, (h_n, c_n) = self.lstm(agent_trajectories)
        # lstm_out: (batch, num_agents, T, 256)
        # æœ€çµ‚éš ã‚ŒçŠ¶æ…‹ã‚’ä½¿ç”¨: (batch, num_agents, 256)
        
        # Self-Attention ã§é‡è¦ãªæ™‚åˆ»ã«ç„¦ç‚¹
        attention_out, _ = self.temporal_attention(
            lstm_out,      # Query
            lstm_out,      # Key
            lstm_out       # Value
        )
        
        # å¹³å‡ãƒ—ãƒ¼ãƒªãƒ³ã‚°
        agent_embeddings = attention_out.mean(dim=2)  # (batch, num_agents, 256)
        
        # ç„¡åŠ¹ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼‰ã‚’ã‚¼ãƒ­ã«ã™ã‚‹
        agent_embeddings = agent_embeddings * valid_mask.unsqueeze(-1)
        
        return agent_embeddings
```

### Map Encoder

```python
class MapEncoder(nn.Module):
    def __init__(self, hidden_dim: int = 256):
        super().__init__()
        # ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆãƒãƒªã‚´ãƒ³ã‚°ãƒ©ãƒ•ï¼‰
        self.gnn_layers = nn.ModuleList([
            GraphAttentionLayer(hidden_dim, hidden_dim, num_heads=8)
            for _ in range(3)
        ])
    
    def forward(
        self,
        map_polygons: torch.Tensor,      # (batch, num_polygons, 8, 2)
        polygon_types: torch.Tensor      # (batch, num_polygons) â† ã‚¿ã‚¤ãƒ—ID
    ) -> torch.Tensor:
        """
        Args:
            map_polygons: å„ãƒãƒªã‚´ãƒ³ã®é ‚ç‚¹åº§æ¨™
            polygon_types: ãƒ¬ãƒ¼ãƒ³ã€åœæ­¢ç·šãªã© ã®ã‚¿ã‚¤ãƒ—

        Returns:
            map_embeddings: (batch, num_polygons, hidden_dim)
        """
        
        # ãƒãƒªã‚´ãƒ³æ¯ã®åŸ‹ã‚è¾¼ã¿
        # å„ãƒãƒªã‚´ãƒ³ã®é ‚ç‚¹ã‚’å¹³å‡åŒ–
        polygon_embeddings = map_polygons.mean(dim=2)  # (batch, num_polygons, 2)
        
        # ã‚¿ã‚¤ãƒ—åŸ‹ã‚è¾¼ã¿ã¨é€£çµ
        type_embeddings = self.type_embedding(polygon_types)
        embeddings = torch.cat([polygon_embeddings, type_embeddings], dim=-1)
        
        # GNNå±¤ã‚’é€šã™
        for gnn_layer in self.gnn_layers:
            embeddings = gnn_layer(embeddings)
        
        return embeddings  # (batch, num_polygons, hidden_dim)
```

### Multimodal Fusion

```python
class MultimodalFusion(nn.Module):
    def __init__(self, hidden_dim: int = 256):
        super().__init__()
        # å„ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‹ã‚‰å…±é€šæ½œåœ¨ç©ºé–“ã¸
        self.ego_projection = nn.Linear(hidden_dim, hidden_dim)
        self.agent_projection = nn.Linear(hidden_dim, hidden_dim)
        self.map_projection = nn.Linear(hidden_dim, hidden_dim)
        
        # Cross-Attention: ãƒ¢ãƒ€ãƒªãƒ†ã‚£é–“ã®ç›¸äº’ä½œç”¨
        self.cross_attention = nn.MultiheadAttention(
            embed_dim=hidden_dim,
            num_heads=8,
            batch_first=True
        )
    
    def forward(
        self,
        ego_embedding: torch.Tensor,          # (batch, 256)
        agent_embeddings: torch.Tensor,       # (batch, 64, 256)
        map_embeddings: torch.Tensor          # (batch, num_polygons, 256)
    ) -> torch.Tensor:
        """è¤‡æ•°ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®ç‰¹å¾´é‡ã‚’çµ±åˆ"""
        
        # æŠ•å½±
        ego_proj = self.ego_projection(ego_embedding)  # (batch, 256)
        agent_proj = self.agent_projection(agent_embeddings)  # (batch, 64, 256)
        map_proj = self.map_projection(map_embeddings)  # (batch, num_polygons, 256)
        
        # å…¨è¦ç´ ã‚’çµ±åˆ
        # Ego ã‚’ä¸­å¿ƒã«ã€Agent ã¨ Map ã‚’ Query ã¨ã—ã¦ Cross-Attention
        fused = self.cross_attention(
            ego_proj.unsqueeze(1),      # Query: (batch, 1, 256)
            torch.cat([agent_proj, map_proj], dim=1),  # Key, Value
            torch.cat([agent_proj, map_proj], dim=1)
        )
        
        return fused[0].squeeze(1)  # (batch, 256)
```

### Trajectory Decoder

```python
class TrajectoryDecoder(nn.Module):
    def __init__(self, num_modes: int = 6, hidden_dim: int = 256):
        super().__init__()
        self.num_modes = num_modes
        self.hidden_dim = hidden_dim
        
        # ãƒ¢ãƒ¼ãƒ‰åˆ¥ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ï¼ˆé‡ã¿ã¯å…±æœ‰ï¼‰
        self.decoder = nn.Sequential(
            nn.Linear(hidden_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 80 * 3)  # 80ã‚¹ãƒ†ãƒƒãƒ— Ã— 3 (x, y, yaw)
        )
    
    def forward(
        self,
        context: torch.Tensor,
        mode_embeddings: torch.Tensor
    ) -> torch.Tensor:
        """
        Args:
            context: (batch, hidden_dim) â† ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼å‡ºåŠ›
            mode_embeddings: (num_modes, hidden_dim) â† ãƒ¢ãƒ¼ãƒ‰å›ºæœ‰ã®åŸ‹ã‚è¾¼ã¿
        
        Returns:
            trajectories: (batch, num_modes, 80, 3)
        """
        
        batch_size = context.shape[0]
        trajectories = []
        
        # å„ãƒ¢ãƒ¼ãƒ‰ã®è»Œè·¡ã‚’ç”Ÿæˆ
        for mode_idx in range(self.num_modes):
            # Context ã¨ãƒ¢ãƒ¼ãƒ‰åŸ‹ã‚è¾¼ã¿ã‚’çµåˆ
            input_vec = context + mode_embeddings[mode_idx]
            
            # ãƒ‡ã‚³ãƒ¼ãƒ‰
            traj = self.decoder(input_vec)  # (batch, 240)
            traj = traj.view(batch_size, 80, 3)  # (batch, 80, 3)
            
            trajectories.append(traj)
        
        return torch.stack(trajectories, dim=1)  # (batch, num_modes, 80, 3)
```

---

## ğŸ“Š ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®è©³ç´°

### å±¤ã”ã¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°

```
Ego Encoder:
  Linear(10, 128):      1.3 K
  Linear(128, 256):    32.8 K
  Linear(256, 256):    65.5 K
  å°è¨ˆ:               ~100 K

Agent Encoder:
  LSTM(10 â†’ 256, 2å±¤): 300 K
  MultiheadAttention:   200 K
  å°è¨ˆ:               ~500 K

Map Encoder:
  GNN Layer Ã— 3:       ~600 K

Fusion Module:
  Projections:         ~200 K
  Cross-Attention:     ~300 K

Decoder:
  Trajectory Decoder:  ~400 K
  Confidence Head:     ~50 K

å…¨ä½“:                ~2.2 M ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
```

### GPU ãƒ¡ãƒ¢ãƒªæ¶ˆè²»é‡

```
ãƒãƒƒãƒã‚µã‚¤ã‚º = 32

Forward Pass:
  Activation ä¿å­˜:      ~800 MB
  
Backward Pass:
  å‹¾é…è¨ˆç®—:            ~400 MB
  Optimizer State:      ~100 MB

åˆè¨ˆ:               ~1.3 GB / GPU
```

---

## ğŸš€ ä½¿ç”¨ä¾‹

### ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã¨æ¨è«–

```python
from src.models.pluto.pluto_model import PlutoModel
import torch

# ãƒ¢ãƒ‡ãƒ«ä½œæˆ
model = PlutoModel(
    num_modes=6,           # äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰æ•°
    hidden_dim=256,
    num_agents=64,
    future_steps=80
)

# GPU ã«è»¢é€
model = model.to("cuda:0")

# ç‰¹å¾´é‡æº–å‚™
feature = builder(scenario, iteration=0)
feature = feature.to_tensor(device="cuda:0")

# æ¨è«–
model.eval()
with torch.no_grad():
    outputs = model(feature)

# å‡ºåŠ›ç¢ºèª
predictions = outputs["prediction"]       # (1, 64, 6, 80, 3)
confidence = outputs["confidence"]        # (1, 64, 6)

print(f"Predictions shape: {predictions.shape}")
print(f"Confidence shape: {confidence.shape}")

# Ego ã®äºˆæ¸¬è»Œè·¡ï¼ˆç¬¬0è¦ç´ ï¼‰
ego_predictions = predictions[0, 0, :, :, :]  # (6, 80, 3)
ego_confidence = confidence[0, 0, :]          # (6,)

for mode in range(6):
    print(f"Mode {mode}: confidence={ego_confidence[mode]:.3f}")
    print(f"  Final position: {ego_predictions[mode, -1, :2]}")
```

### è¨“ç·´

```python
from torch.optim import Adam
from src.optim.warmup_cos_lr import WarmupCosLR

# ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼
optimizer = Adam(model.parameters(), lr=1e-3)
scheduler = WarmupCosLR(
    optimizer=optimizer,
    warmup_steps=1000,
    total_steps=100000,
    learning_rate=1e-3
)

# è¨“ç·´ãƒ«ãƒ¼ãƒ—
for epoch in range(50):
    for batch_idx, batch in enumerate(train_loader):
        # Forward
        outputs = model(batch)
        predictions = outputs["prediction"]
        confidence = outputs["confidence"]
        
        # Loss è¨ˆç®—
        loss = compute_loss(
            predictions,
            confidence,
            batch["target"],
            batch["valid_mask"]
        )
        
        # Backward
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        scheduler.step()
        
        if batch_idx % 100 == 0:
            print(f"Loss: {loss.item():.4f}")
```

---

## ğŸ” ãƒ‡ãƒãƒƒã‚°ãƒ»å¯è¦–åŒ–

### ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã®ç¢ºèª

```python
def validate_model_output(outputs):
    """ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã®å¦¥å½“æ€§æ¤œè¨¼"""
    
    predictions = outputs["prediction"]
    confidence = outputs["confidence"]
    
    # å½¢çŠ¶ãƒã‚§ãƒƒã‚¯
    assert predictions.shape[-1] == 3, "è»Œè·¡ã¯3æ¬¡å…ƒï¼ˆx, y, yawï¼‰"
    assert predictions.shape[-2] == 80, "äºˆæ¸¬ã‚¹ãƒ†ãƒƒãƒ—ã¯80"
    assert predictions.shape[-3] == 6, "ãƒ¢ãƒ¼ãƒ‰æ•°ã¯6"
    
    # ç¢ºç‡ãƒã‚§ãƒƒã‚¯
    assert confidence.min() >= 0, "ç¢ºç‡ãŒè² "
    assert confidence.max() <= 1, "ç¢ºç‡ãŒ1è¶…é"
    assert torch.allclose(confidence.sum(dim=-1), torch.ones(1)), "ç¢ºç‡åˆè¨ˆãŒ1ã§ãªã„"
    
    print("âœ“ ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ãŒå¦¥å½“")

outputs = model(feature)
validate_model_output(outputs)
```

### äºˆæ¸¬è»Œè·¡ã®å¯è¦–åŒ–

```python
import matplotlib.pyplot as plt

def visualize_model_predictions(predictions, confidence, colors=['r', 'g', 'b', 'orange', 'purple', 'brown']):
    """6ã¤ã®ãƒ¢ãƒ¼ãƒ‰äºˆæ¸¬ã‚’å¯è¦–åŒ–"""
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))
    
    # è»Œè·¡ãƒ—ãƒ­ãƒƒãƒˆ
    for mode in range(6):
        traj = predictions[0, 0, mode, :, :2].cpu().numpy()
        conf = confidence[0, 0, mode].cpu().item()
        
        ax1.plot(traj[:, 0], traj[:, 1], 
                color=colors[mode], alpha=0.7,
                label=f"Mode {mode} (p={conf:.3f})")
    
    ax1.set_xlabel("X [m]")
    ax1.set_ylabel("Y [m]")
    ax1.set_title("Multimodal Trajectory Predictions")
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.set_aspect("equal")
    
    # ç¢ºç‡åˆ†å¸ƒãƒ—ãƒ­ãƒƒãƒˆ
    confs = confidence[0, 0].cpu().numpy()
    ax2.bar(range(6), confs, color=colors)
    ax2.set_xlabel("Mode")
    ax2.set_ylabel("Probability")
    ax2.set_title("Mode Confidence Distribution")
    ax2.set_ylim([0, 1])
    
    plt.tight_layout()
    plt.savefig("model_predictions.png")
    plt.show()

visualize_model_predictions(predictions, confidence)
```

---

## ğŸ“š é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«

- [../custom_training/custom_training_builder.md](../custom_training/custom_training_builder.md) - è¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
- [../metrics/evaluation_metrics.md](../metrics/evaluation_metrics.md) - è©•ä¾¡
