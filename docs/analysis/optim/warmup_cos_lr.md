# WarmupCosLR å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ© è©³ç´°ã‚¬ã‚¤ãƒ‰

## ğŸ“‹ æ¦‚è¦

`WarmupCosLR` ã¯ã€**ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—æ®µéš + ä½™å¼¦ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°æ®µéš** ã®2æ®µéšã‹ã‚‰æ§‹æˆã•ã‚Œã‚‹å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã§ã™ã€‚

---

## ğŸ¯ å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æ¦‚å¿µ

### ã‚¹ãƒ†ãƒƒãƒ—1: ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—æ®µéš (0ï½steps)

```
å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ« (ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—)

LR
  â”‚
  â”‚  ç›®æ¨™LR
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                     â”‚ â† ç›®æ¨™ã«åˆ°é”
  â”‚        /â”‚           â”‚
  â”‚       / â”‚           â”‚
  â”‚      /  â”‚ ã‚¦ã‚©ãƒ¼ãƒ    â”‚
  â”‚     /   â”‚  ã‚¢ãƒƒãƒ—   â”‚
  â”‚    /    â”‚           â”‚
  â”‚   /     â”‚           â”‚
åˆæœŸLR â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€ã‚±â”€â”€â”€ æ™‚åˆ»
  0 steps  warmup_steps    predict_steps

ç›®çš„: ãƒ¢ãƒ‡ãƒ«ãŒå®‰å®šçš„ã«å­¦ç¿’ã‚’å§‹ã‚ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã€
     å¾ã€…ã«å­¦ç¿’ç‡ã‚’ä¸Šã’ã¦ã„ã
```

**å®Ÿè£…**:
```python
# ç·šå½¢ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
lr_t = initial_lr + (target_lr - initial_lr) * (t / warmup_steps)

# ä¾‹:
# initial_lr = 1e-5
# target_lr = 1e-3
# warmup_steps = 1000

# t=0:    lr = 1e-5
# t=500:  lr = 5e-4
# t=1000: lr = 1e-3 (åˆ°é”)
```

### ã‚¹ãƒ†ãƒƒãƒ—2: ä½™å¼¦ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°æ®µéš (warmup_stepsï½total_steps)

```
å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ« (ä½™å¼¦ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°)

LR
  â”‚
  â”‚  ç›®æ¨™LR â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚         â”‚\            
  â”‚         â”‚ \   ä½™å¼¦    
  â”‚         â”‚  \  æ›²ç·š    
  â”‚         â”‚   \        
æœ€å°LR â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ æ™‚åˆ»
      warmup_steps   total_steps

ç›®çš„: å­¦ç¿’ç‡ã‚’å¾ã€…ã«ä¸‹ã’ã‚‹ã“ã¨ã§ã€
     ãƒ¢ãƒ‡ãƒ«ã‚’å±€æ‰€æœ€é©è§£ã«åæŸã•ã›ã‚‹
```

**å®Ÿè£…**:
```python
# ä½™å¼¦ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°
progress = (t - warmup_steps) / (total_steps - warmup_steps)
lr_t = min_lr + (target_lr - min_lr) * (1 + cos(Ï€ * progress)) / 2

# ä¾‹:
# progress=0.0: cos(0) = 1  â†’ lr = target_lr (æœ€å¤§)
# progress=0.5: cos(Ï€/2) = 0 â†’ lr = (target_lr + min_lr) / 2 (ä¸­é–“)
# progress=1.0: cos(Ï€) = -1 â†’ lr = min_lr (æœ€å°)
```

---

## ğŸ”§ å®Ÿè£…ã‚³ãƒ¼ãƒ‰

### ã‚¯ãƒ©ã‚¹å®šç¾©

```python
class WarmupCosLR(LRScheduler):
    def __init__(
        self,
        optimizer: torch.optim.Optimizer,
        warmup_steps: int = 1000,
        total_steps: int = 100000,
        learning_rate: float = 1e-3,
        min_lr: float = 0.0,
        warmup_factor: float = 0.1,
    ):
        """
        Args:
            optimizer: PyTorch ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼
            warmup_steps: ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—æœŸé–“ [ã‚¹ãƒ†ãƒƒãƒ—æ•°]
            total_steps: ç·è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—æ•°
            learning_rate: ç›®æ¨™å­¦ç¿’ç‡ï¼ˆã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å¾Œï¼‰
            min_lr: æœ€å°å­¦ç¿’ç‡ï¼ˆã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°æœ€å°å€¤ï¼‰
            warmup_factor: ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—åˆæœŸå­¦ç¿’ç‡ã®å€æ•°
                          åˆæœŸLR = learning_rate * warmup_factor
        """
        self.optimizer = optimizer
        self.warmup_steps = warmup_steps
        self.total_steps = total_steps
        self.learning_rate = learning_rate
        self.min_lr = min_lr
        self.warmup_factor = warmup_factor
        
        # åˆæœŸå­¦ç¿’ç‡ã®è¨ˆç®—
        self.initial_lr = learning_rate * warmup_factor
        
        # ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—
        self.current_step = 0
        
        super().__init__(optimizer)
    
    def step(self) -> None:
        """å„ã‚¹ãƒ†ãƒƒãƒ—ã§å­¦ç¿’ç‡ã‚’æ›´æ–°"""
        
        if self.current_step < self.warmup_steps:
            # ========== ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—æ®µéš ==========
            progress = self.current_step / self.warmup_steps
            lr = self.initial_lr + (self.learning_rate - self.initial_lr) * progress
            
        else:
            # ========== ä½™å¼¦ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°æ®µéš ==========
            annealing_steps = self.current_step - self.warmup_steps
            annealing_total = self.total_steps - self.warmup_steps
            
            progress = annealing_steps / annealing_total
            
            # ä½™å¼¦é–¢æ•°: cos(Ï€ * progress)
            # progress=0: cos(0) = 1
            # progress=1: cos(Ï€) = -1
            cos_factor = (1 + math.cos(math.pi * progress)) / 2
            
            lr = self.min_lr + (self.learning_rate - self.min_lr) * cos_factor
        
        # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã®å­¦ç¿’ç‡ã‚’æ›´æ–°
        for param_group in self.optimizer.param_groups:
            param_group["lr"] = lr
        
        self.current_step += 1
```

---

## ğŸ“Š ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åŠ¹æœ

### warmup_factor ã®é¸æŠ

```python
# warmup_factor = 0.1 (æ¨å¥¨)
initial_lr = 1e-3 * 0.1 = 1e-4

# è¨“ç·´é–‹å§‹æ™‚:
# å­¦ç¿’ç‡ãŒä½ã„ã®ã§ã€å¤§ããªæ›´æ–°ã«ã‚ˆã‚‹ç™ºæ•£ã‚’é˜²ã
# â†’ å®‰å®šã—ãŸå­¦ç¿’ã®é–‹å§‹

# warmup_factor = 1.0 (éæ¨å¥¨)
initial_lr = 1e-3

# æœ€åˆã‹ã‚‰ç›®æ¨™å­¦ç¿’ç‡ã§é–‹å§‹
# â†’ ä¸å®‰å®šãªå­¦ç¿’ã€loss ãŒç™ºæ•£ã™ã‚‹å¯èƒ½æ€§

# warmup_factor = 0.01 (æ§ãˆç›®)
initial_lr = 1e-5

# éå¸¸ã«å¾ã€…ã«å­¦ç¿’ç‡ã‚’ä¸Šã’ã‚‹
# â†’ åæŸã¯é…ã„ã€å®‰å®šæ€§ã¯é«˜ã„
```

### min_lr ã®é¸æŠ

```python
# min_lr = 0.0 (æ¨å¥¨)
# æœ€çµ‚çš„ã«å­¦ç¿’ç‡ã‚’0ã¾ã§ä½ä¸‹ã•ã›ã€å®Œå…¨ã«åæŸ

# min_lr = 1e-6 (æ¨å¥¨)
# æœ€çµ‚çš„ãªå¾®èª¿æ•´ã®ãŸã‚ã®æœ€å°å­¦ç¿’ç‡ã‚’ç¶­æŒ
# â†’ ã‚ãšã‹ãªæ›´æ–°ã§éå­¦ç¿’ã‚’é˜²ã

# min_lr = 1e-4 (éæ¨å¥¨)
# å­¦ç¿’ç‡ã®ä½ä¸‹å¹…ãŒå°ã•ãã€åæŸãŒé…ã„
```

---

## ğŸš€ ä½¿ç”¨ä¾‹

### åŸºæœ¬çš„ãªè¨“ç·´ãƒ«ãƒ¼ãƒ—

```python
import torch
import torch.nn as nn
from torch.optim import Adam
from src.optim.warmup_cos_lr import WarmupCosLR

# ãƒ¢ãƒ‡ãƒ«å®šç¾©
model = PlutoModel(...)

# ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼
optimizer = Adam(model.parameters(), lr=1e-3)

# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼
total_epochs = 50
epoch_steps = len(train_loader)
total_steps = total_epochs * epoch_steps

scheduler = WarmupCosLR(
    optimizer=optimizer,
    warmup_steps=1000,         # æœ€åˆã®1000ã‚¹ãƒ†ãƒƒãƒ—ã§ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
    total_steps=total_steps,   # å…¨50ã‚¨ãƒãƒƒã‚¯
    learning_rate=1e-3,        # ç›®æ¨™å­¦ç¿’ç‡
    min_lr=1e-6,              # æœ€å°å­¦ç¿’ç‡
    warmup_factor=0.1         # åˆæœŸLR = 1e-3 * 0.1 = 1e-4
)

# è¨“ç·´ãƒ«ãƒ¼ãƒ—
for epoch in range(total_epochs):
    for batch_idx, batch in enumerate(train_loader):
        # Forward pass
        outputs = model(batch)
        loss = compute_loss(outputs, batch)
        
        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # å­¦ç¿’ç‡æ›´æ–°
        scheduler.step()
        
        if batch_idx % 100 == 0:
            current_lr = optimizer.param_groups[0]['lr']
            print(f"Epoch {epoch}, Batch {batch_idx}, LR: {current_lr:.2e}, Loss: {loss:.4f}")
```

### Hydra è¨­å®šã§ã®ä½¿ç”¨

```yaml
# config/training/train_pluto.yaml

scheduler:
  _target_: src.optim.warmup_cos_lr.WarmupCosLR
  
  # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—è¨­å®š
  warmup_steps: 1000         # ç´„15åˆ†ï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚º64, GPU1æšï¼‰
  warmup_factor: 0.1         # åˆæœŸLR = LR * 0.1
  
  # ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°è¨­å®š
  learning_rate: 1e-3        # ç›®æ¨™å­¦ç¿’ç‡
  min_lr: 1e-6              # æœ€å°å­¦ç¿’ç‡
  total_steps: 500000        # 50ã‚¨ãƒãƒƒã‚¯åˆ†
```

Python ã§ã®èª­ã¿è¾¼ã¿:

```python
from hydra.utils import instantiate
import yaml

with open("config/training/train_pluto.yaml") as f:
    config = yaml.safe_load(f)

scheduler = instantiate(
    config["scheduler"],
    optimizer=optimizer
)
```

---

## ğŸ“ˆ å­¦ç¿’ç‡ã®å¯è¦–åŒ–

### ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¡¨ç¤ºã‚³ãƒ¼ãƒ‰

```python
import matplotlib.pyplot as plt
import numpy as np

def visualize_schedule(warmup_steps, total_steps, learning_rate, min_lr):
    lrs = []
    steps = range(total_steps)
    
    for step in steps:
        if step < warmup_steps:
            # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
            progress = step / warmup_steps
            lr = learning_rate * 0.1 + (learning_rate - learning_rate * 0.1) * progress
        else:
            # ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°
            progress = (step - warmup_steps) / (total_steps - warmup_steps)
            cos_factor = (1 + np.cos(np.pi * progress)) / 2
            lr = min_lr + (learning_rate - min_lr) * cos_factor
        
        lrs.append(lr)
    
    plt.figure(figsize=(12, 4))
    plt.plot(lrs)
    plt.xlabel("Training Steps")
    plt.ylabel("Learning Rate")
    plt.title("WarmupCosLR Schedule")
    plt.grid(True, alpha=0.3)
    
    # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—æœŸé–“ã‚’æ˜ç¤º
    plt.axvline(warmup_steps, color='r', linestyle='--', alpha=0.5, label='Warmup End')
    plt.legend()
    
    plt.tight_layout()
    plt.savefig("lr_schedule.png", dpi=150)
    plt.show()

# å®Ÿè¡Œä¾‹
visualize_schedule(
    warmup_steps=1000,
    total_steps=100000,
    learning_rate=1e-3,
    min_lr=1e-6
)
```

---

## ğŸ” ãƒ‡ãƒãƒƒã‚°ãƒ»ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

### å­¦ç¿’ç‡ã®ãƒ­ã‚°è¨˜éŒ²

```python
from tensorboard.compat.tensorflow_stub import io as tb_io
import torch

class LRLogger:
    def __init__(self, writer=None):
        self.writer = writer
        self.step = 0
    
    def log(self, optimizer, loss):
        current_lr = optimizer.param_groups[0]['lr']
        
        if self.writer:
            self.writer.add_scalar("lr", current_lr, self.step)
            self.writer.add_scalar("loss", loss, self.step)
        
        self.step += 1

# ä½¿ç”¨
from torch.utils.tensorboard import SummaryWriter

writer = SummaryWriter("logs/experiment_1")
lr_logger = LRLogger(writer)

# è¨“ç·´ãƒ«ãƒ¼ãƒ—å†…
for batch_idx, batch in enumerate(train_loader):
    loss = train_one_batch(batch)
    optimizer.step()
    scheduler.step()
    
    lr_logger.log(optimizer, loss)

writer.close()
```

### ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼çŠ¶æ…‹ã®æ¤œè¨¼

```python
def validate_scheduler(scheduler, total_steps=1000):
    """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®å‹•ä½œã‚’æ¤œè¨¼"""
    
    lrs = []
    for _ in range(total_steps):
        lrs.append(scheduler.optimizer.param_groups[0]['lr'])
        scheduler.step()
    
    print(f"æœ€å°å­¦ç¿’ç‡: {min(lrs):.2e}")
    print(f"æœ€å¤§å­¦ç¿’ç‡: {max(lrs):.2e}")
    print(f"åˆæœŸå­¦ç¿’ç‡: {lrs[0]:.2e}")
    print(f"æœ€çµ‚å­¦ç¿’ç‡: {lrs[-1]:.2e}")
    
    # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—æ®µéšã®ç¢ºèª
    warmup_lrs = lrs[:1000]
    print(f"ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ãŒä¸Šæ˜‡å‚¾å‘ã‹: {warmup_lrs[-1] > warmup_lrs[0]}")
    
    # ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°æ®µéšã®ç¢ºèª
    anneal_lrs = lrs[1000:]
    print(f"ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°ãŒä¸‹é™å‚¾å‘ã‹: {anneal_lrs[-1] < anneal_lrs[0]}")

validate_scheduler(scheduler)
```

---

## ğŸ“š é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«

- [../custom_training/custom_training_builder.md](../custom_training/custom_training_builder.md) - è¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
- [../models/pluto_model.md](../models/pluto_model.md) - ãƒ¢ãƒ‡ãƒ«å®Ÿè£…
