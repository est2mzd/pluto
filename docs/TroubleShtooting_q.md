# Pluto Training Failure: q ãŒ NaN / Inf ã«ãªã‚‹å•é¡Œã®æ•´ç†ã¨å¯¾ç­–

## 1. ç¾çŠ¶ã®æ•´ç†ï¼ˆäº‹å®Ÿãƒ™ãƒ¼ã‚¹ï¼‰

### 1.1 ç™ºç”Ÿã—ã¦ã„ã‚‹ã‚¨ãƒ©ãƒ¼

å­¦ç¿’ä¸­ã€ä»¥ä¸‹ã® assert ã§åœæ­¢ã™ã‚‹ã€‚

```python
assert torch.isfinite(q).all()
```

ç™ºç”Ÿç®‡æ‰€ï¼š

```
PlanningDecoder.forward()
```

`q` ã¯ PlanningDecoder å†…éƒ¨ã§ç”Ÿæˆã•ã‚Œã‚‹ **trajectory query tensor**ã€‚

---

### 1.2 åœ°å›³ï¼ˆmap.gpkgï¼‰ã«ã¤ã„ã¦

ç¢ºèªçµæœï¼š

* `/nuplan/dataset/maps/us-ma-boston/9.12.1817/map.gpkg` â†’ **å­˜åœ¨**
* `/nuplan/dataset/maps/us-nv-las-vegas-strip/9.15.1915/map.gpkg` â†’ **å­˜åœ¨**

ã‚ˆã£ã¦ï¼š

âŒ map.gpkg ã® **å®Ÿä½“æ¬ å¦‚ãŒç›´æ¥ã®åŸå› ã§ã¯ãªã„**

ï¼ˆâ€» map ã‚’ä¸€æ™‚çš„ã«å‹•ã‹ã—ãŸã“ã¨ã§åˆ¥ã‚¨ãƒ©ãƒ¼ã¯å‡ºãŸãŒã€ç¾åœ¨ã® q NaN å•é¡Œã¨ã¯ç‹¬ç«‹ï¼‰

---

## 2. q ãŒã©ã“ã§ä½œã‚‰ã‚Œã¦ã„ã‚‹ã‹ï¼ˆã‚³ãƒ¼ãƒ‰æ§‹é€ ï¼‰

```python
r_emb = self.r_encoder(...)
m_emb = self.m_emb
q = self.q_proj(torch.cat([r_emb, m_emb], dim=-1))

for blk in self.decoder_blocks:
    q = blk(...)
    assert torch.isfinite(q).all()
```

NaN/Inf ã®æ··å…¥ãƒã‚¤ãƒ³ãƒˆã¯ **2 ç³»çµ±ã®ã¿**ã€‚

---

## 3. NaN/Inf ã®ç¢ºå®šçš„ç™ºç”Ÿãƒ«ãƒ¼ãƒˆ

### ç³»çµ± Aï¼šPointsEncoder ã«ã€Œå…¨ False maskã€ãŒå…¥ã‚‹

#### å•é¡Œç®‡æ‰€

```python
r_valid_mask = r_valid_mask.view(bs * R, P)
r_emb = self.r_encoder(r_feature, r_valid_mask)
```

`PointsEncoder.forward()` å†…éƒ¨ã§ã¯ï¼š

```python
x_valid = x[mask]          # mask ãŒå…¨ False â†’ ç©º
BatchNorm1d(x_valid)      # ä¸å®šæŒ™å‹• / NaN ç™ºç”Ÿã—ã†ã‚‹
```

#### ç™ºç”Ÿæ¡ä»¶

* reference_line ãŒ **å…¨ invalid** ãªã‚µãƒ³ãƒ—ãƒ«ãŒæ··å…¥
* Boston ãƒ‡ãƒ¼ã‚¿ã§ã‚‚å®Ÿéš›ã«èµ·ãã†ã‚‹ï¼ˆäº‹å®Ÿï¼‰

#### çµæœ

* `r_emb` ã« NaN
* `q = Linear([r_emb, m_emb])` ã§å³ NaN

---

### ç³»çµ± Bï¼šMultiheadAttention ã«ã€Œå…¨ãƒã‚¹ã‚¯ç³»åˆ—ã€ãŒå…¥ã‚‹

#### å•é¡Œç®‡æ‰€

```python
self.cross_attn(
    tgt, memory, memory,
    key_padding_mask=enc_key_padding_mask
)
```

#### PyTorch MHA ã®ä»•æ§˜

* key_padding_mask ãŒ **å…¨ True**
* attention score = å…¨ -inf
* softmax â†’ NaN

#### ç™ºç”Ÿæ¡ä»¶

* encoder å´å‡ºåŠ›ãŒå…¨ invalid
* ã¾ãŸã¯ scenario/map ã®ä¸æ•´åˆã§ encoder feature ãŒå…¨ mask

---

## 4. ã“ã‚Œã¾ã§ã®å¯¾ç­–ãŒåŠ¹ã‹ãªã‹ã£ãŸç†ç”±

| è©¦ã—ãŸå¯¾ç­–           | åŠ¹æœãŒãªã‹ã£ãŸç†ç”±                                |
| --------------- | ---------------------------------------- |
| `x / sqrt(dim)` | planning_decoder ã§ã¯ scale ä¸è¦ã€‚NaN ã®æ ¹æºã§ã¯ãªã„ |
| dropout èª¿æ•´      | NaN ç™ºç”Ÿå¾Œã®æ“ä½œãªã®ã§ç„¡æ„å‘³                         |
| attn_norm è¿½åŠ     | Decoder å´ã«ã¯å­˜åœ¨ã—ãªã„                         |

ğŸ‘‰ **NaN ã¯ã€Œæ•°å€¤ç™ºæ•£ã€ã§ã¯ãªãã€Œç„¡åŠ¹å…¥åŠ›ã€ç”±æ¥**

---

## 5. æœ€å°ãƒ»æ­£å½“ãªå¯¾ç­–æ–¹é‡ï¼ˆæ¨å¥¨é †ï¼‰

### å¯¾ç­–â‘ ï¼šPointsEncoder ã‚’ã€Œå…¨ False mask å®‰å…¨ã€ã«ã™ã‚‹ï¼ˆæœ€é‡è¦ï¼‰

**æ„å›³**ï¼š

* ç„¡åŠ¹ reference_line ã‚’ã€Œã‚¼ãƒ­ç‰¹å¾´ã€ã¨ã—ã¦æ‰±ã†
* NaN ã‚’ä½œã‚‰ãªã„

#### æœ€å°ä¿®æ­£æ¡ˆï¼ˆä¾‹ï¼‰

```python
# PointsEncoder.forward ã®å†’é ­
if mask.sum() == 0:
    return torch.zeros(bs, self.encoder_channel, device=device)
```

â€» ä¸è¦ãªãƒ­ã‚¸ãƒƒã‚¯å¤‰æ›´ãªã—

---

### å¯¾ç­–â‘¡ï¼šDecoder å´ã§ã€Œå…¨ãƒã‚¹ã‚¯ç³»åˆ—ã€ã‚’1ç‚¹ã ã‘è§£é™¤

**æ„å›³**ï¼š

* MultiheadAttention ã® softmax NaN ã‚’é˜²ã

```python
all_e = enc_key_padding_mask.all(dim=1)
enc_key_padding_mask[all_e, 0] = False
```

â€» ã“ã‚Œã¯ **NaN å›é¿ã®å®‰å…¨å¼**ã€‚æ ¹æœ¬è§£æ±ºã¯â‘ ã€‚

---

## 6. åŸå› åˆ‡ã‚Šåˆ†ã‘ç”¨ã®æœ€å°ãƒ­ã‚°ï¼ˆæ¨å¥¨ï¼‰

```python
if not torch.isfinite(q).all():
    print(
        'r_emb finite=', torch.isfinite(r_emb).all().item(),
        'enc_mask all_true=', enc_key_padding_mask.all(dim=1).any().item(),
    )
    raise
```

ã“ã‚Œã§ï¼š

* r_emb ãŒ NaN â†’ **ç³»çµ± A**
* block å¾Œã§ NaN â†’ **ç³»çµ± B**

ãŒå³åˆ¤åˆ¥å¯èƒ½ã€‚

---

## 7. ã¾ã¨ã‚ï¼ˆé‡è¦ï¼‰

* âŒ map.gpkg ã¯åŸå› ã§ã¯ãªã„
* âŒ attention ã®æ•°å€¤å®‰å®šåŒ–ã§ã¯è§£æ±ºã—ãªã„
* âœ… åŸå› ã¯ã€Œå…¨ invalid å…¥åŠ›ã€
* âœ… å¯¾ç­–ã¯ mask / empty-input handling

---

## 8. æ¬¡ã«ã‚„ã‚‹ã¹ãã“ã¨ï¼ˆæœ€çŸ­ï¼‰

1. PointsEncoder ã« **å…¨ False mask å¯¾ç­–**ã‚’å…¥ã‚Œã‚‹
2. ãã®ã¾ã¾å†å®Ÿè¡Œ
3. ã¾ã è½ã¡ãŸã‚‰ Decoder å´å…¨ãƒã‚¹ã‚¯å¯¾ç­–ã‚’è¿½åŠ 

ã“ã®é †ã§ã€**æœ€å°å¤‰æ›´ãƒ»æœ€å¤§ç¢ºåº¦**ã§ç›´ã‚Šã¾ã™ã€‚
